# Training a Large Language Model with AutoVAS NVD Dataset

Train a Large Language Model (LLM) to automatically identify and fix code vulnerabilities using inputs from the AutoVAS NVD dataset.

## Workflow

### Step 1: Data Preparation
- **Script Used**: `AutoVAS_Dataset_Formatting.py`
- **Objective**: Generate a CSV file containing pairs of vulnerable and patched code snippets from the AutoVAS dataset.
- **Details**: This script processes files in the NVD directory, extracting code snippets from both vulnerable and patched files, and saves them in a structured CSV format.

### Step 2: Training the LLM
- **Current Script**: `LLM_Train_Final.ipynb`
- **Objective**: Use the data generated in the first step to train an LLM.
- **Steps**:
  1. Load the CSV file with vulnerable and patched code.
  2. Split the data into training and testing datasets.
  3. Form a custom dataset with instructions to train the LLM.

## Model Training Attempts

### Models Tried
- **Google Gemma**
- **NexaAIDev/Octopus-v2**

### Challenges
- Both models have billions of parameters, resulting in out-of-memory errors on the available GPU.
- Attempted to train on the TAMU HPRC computing cluster but faced similar memory issues.

### Alternative Approach
- Recommendations included using more GPUs or implementing distributed training.

## Current Solution
- **Model Used**: `Salesforce/codegen-350M-mono`
- **Parameters**: 350 million
- **Outcome**: Successfully trained on a single GPU.
- **Results**: Mixed performanceâ€”some code vulnerabilities were fixed correctly, while others were not.

## Next Steps and To-Do List

### Evaluation Methodology
- **Challenge**: Evaluating the performance of code output is complex since it's not a simple yes/no check.
- **Suggestion**: Run the model's output through static analyzers to verify if the vulnerabilities have been fixed.

### Automated Test Case Generation
- **Goal**: Use a custom dataset to automatically generate test cases for both training and testing phases.
- **Benefit**: Improves the robustness of the model and provides a more comprehensive evaluation of its performance.


