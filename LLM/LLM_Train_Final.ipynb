{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "896c976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas torch trl transformers huggingface_hub scikit-learn datasets  -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b83b9586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read DataFrame back from a CSV file\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "\n",
    "df.fillna({'Vulnerable Code': ''}, inplace=True)\n",
    "df.fillna({'Patched Code': ''}, inplace=True)\n",
    "\n",
    "# Convert DataFrame columns back to lists\n",
    "input_data = df['Vulnerable Code'].tolist()\n",
    "output_data = df['Patched Code'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a1205b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static void CVE_2011_4324_PATCHED_encode_share_access(struct xdr_stream *xdr, fmode_t fmode)\n",
      "{\n",
      "\t__be32 *p;\n",
      "\n",
      "\tRESERVE_SPACE(8);\n",
      "\tswitch (fmode & (FMODE_READ|FMODE_WRITE)) {\n",
      "\t\tcase FMODE_READ:\n",
      "\t\t\tWRITE32(NFS4_SHARE_ACCESS_READ);\n",
      "\t\t\tbreak;\n",
      "\t\tcase FMODE_WRITE:\n",
      "\t\t\tWRITE32(NFS4_SHARE_ACCESS_WRITE);\n",
      "\t\t\tbreak;\n",
      "\t\tcase FMODE_READ|FMODE_WRITE:\n",
      "\t\t\tWRITE32(NFS4_SHARE_ACCESS_BOTH);\n",
      "\t\t\tbreak;\n",
      "\t\tdefault:\n",
      "\t\t\tWRITE32(0);\n",
      "\t}\n",
      "\tWRITE32(0);\t\t/* for linux, share_deny = 0 always */\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "337f95f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming training_df is your DataFrame containing the training data\n",
    "# Split the dataset into training and testing sets\n",
    "train_inputs, test_inputs, train_outputs, test_outputs = train_test_split(input_data, output_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97093948",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "input_data = []\n",
    "output_data = []\n",
    "for filename in os.listdir(directory_path):\n",
    "    if \"PATCHED\" in filename:\n",
    "        # Find the corresponding vulnerable file\n",
    "        vulnerable_filename = filename.replace('PATCHED', 'VULN')\n",
    "        # Read and store the patched code\n",
    "        with open(os.path.join(directory_path, filename), 'r') as patched_file:\n",
    "            patched_code = patched_file.read()\n",
    "        with open(os.path.join(directory_path, vulnerable_filename), 'r') as file:\n",
    "            vulnerable_code = file.read()\n",
    "        if vulnerable_code != None and patched_code != None:\n",
    "            vulnerable_codes.append(vulnerable_code)\n",
    "            patched_codes.append(patched_code)\n",
    "            input_data.append(vulnerable_code)\n",
    "            output_data.append(patched_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2db50d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769\n",
      "193\n"
     ]
    }
   ],
   "source": [
    "print(len(train_inputs))\n",
    "print(len(test_outputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6b2f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GemmaForCausalLM\n",
    "\n",
    "#model_id = \"google/gemma-7b\"\n",
    "#model_id = \"NexaAIDev/Octopus-v2\"\n",
    "model_id = \"Salesforce/codegen-350M-mono\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, torch_dtype=torch.bfloat16, device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da5c2907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "common_instruction = 'You are given vulnerable code as input. Output the fixed code'\n",
    "\n",
    "data_dict = {\n",
    "    'instruction': [common_instruction] * len(train_inputs),\n",
    "    'input': train_inputs,\n",
    "    'output': train_outputs\n",
    "} \n",
    "custom_dataset = Dataset.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8652e729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sravyagopireddy/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:245: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82919b1e2da842b394c9e814cf97354d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/769 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sravyagopireddy/.local/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='579' max='579' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [579/579 04:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.192400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.062400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.949800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.856700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.860300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.800300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.754500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.762900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.769600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory outputs/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=579, training_loss=0.888243469343696, metrics={'train_runtime': 300.2549, 'train_samples_per_second': 7.683, 'train_steps_per_second': 1.928, 'total_flos': 4278828138233856.0, 'train_loss': 0.888243469343696, 'epoch': 3.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "\n",
    "\n",
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['instruction'])):\n",
    "        text = f\"### Instruction: {example['instruction'][i]}\\n ### Input: {example['input'][i]}\\n ### Output: {example['output'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=custom_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        logging_steps=50,\n",
    "        output_dir=\"outputs\",\n",
    "        gradient_accumulation_steps=1,\n",
    "        per_device_train_batch_size=4,\n",
    "    ),\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    \n",
    ")\n",
    "tokenizer.padding_side = 'right'\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebf692de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dict = {\n",
    "    'instruction': [common_instruction] * len(test_inputs),\n",
    "    'input': test_inputs,\n",
    "} \n",
    "test_dataset = Dataset.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0f3ee7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(common_instruction + test_inputs[0], return_tensors=\"pt\").to(model.device)\n",
    "input_length = input_ids[\"input_ids\"].shape[1]\n",
    "outputs = model.generate(\n",
    "input_ids=input_ids[\"input_ids\"], \n",
    "        max_length=2000,\n",
    "        do_sample=False)\n",
    "generated_sequence = outputs[:, input_length:].tolist()\n",
    "res = tokenizer.decode(generated_sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "860e2f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "again:\n",
      "\tswitch (proto) {\n",
      "\tcase __constant_htons(ETH_P_IP): {\n",
      "\t\tconst struct iphdr *iph;\n",
      "\t\tstruct iphdr _iph;\n",
      "ip:\n",
      "\t\tiph = skb_header_pointer(skb, nhoff, sizeof(_iph), &_iph);\n",
      "\t\tif (!iph)\n",
      "\t\t\treturn false;\n",
      "\n",
      "\t\tif (ip_is_fragment(iph))\n",
      "\t\t\tip_proto = 0;\n",
      "\t\telse\n",
      "\t\t\tip_proto = iph->protocol;\n",
      "\t\tiph_to_flow_copy_addrs(flow, iph);\n",
      "\t\tnhoff += iph->ihl * 4;\n",
      "\t\tbreak;\n",
      "\t}\n",
      "\tcase __constant_htons(ETH_P_IPV6): {\n",
      "\t\tconst struct ipv6hdr *iph;\n",
      "\t\tstruct ipv6hdr _iph;\n",
      "ipv6:\n",
      "\t\tiph = skb_header_pointer(skb, nhoff, sizeof(_iph), &_iph);\n",
      "\t\tif (!iph)\n",
      "\t\t\treturn false;\n",
      "\n",
      "\t\tip_proto = iph->nexthdr;\n",
      "\t\tflow->src = (__force __be32)ipv6_addr_hash(&iph->saddr);\n",
      "\t\tflow->dst = (__force __be32)ipv6_addr_hash(&iph->daddr);\n",
      "\t\tnhoff += sizeof(struct ipv6hdr);\n",
      "\t\tbreak;\n",
      "\t}\n",
      "\tcase __constant_htons(ETH_P_8021Q): {\n",
      "\t\tconst struct vlan_hdr *vlan;\n",
      "\t\tstruct vlan_hdr _vlan;\n",
      "\n",
      "\t\tvlan = skb_header_pointer(skb, nhoff, sizeof(_vlan), &_vlan);\n",
      "\t\tif (!vlan)\n",
      "\t\t\treturn false;\n",
      "\n",
      "\t\tproto = vlan->h_vlan_encapsulated_proto;\n",
      "\t\tnhoff += sizeof(*vlan);\n",
      "\t\tgoto again;\n",
      "\t}\n",
      "\tcase __constant_htons(ETH_P_PPP_SES): {\n",
      "\t\tstruct {\n",
      "\t\t\tstruct pppoe_hdr hdr;\n",
      "\t\t\t__be16 proto;\n",
      "\t\t} *hdr, _hdr;\n",
      "\t\thdr = skb_header_pointer(skb, nhoff, sizeof(_hdr), &_hdr);\n",
      "\t\tif (!hdr)\n",
      "\t\t\treturn false;\n",
      "\t\tproto = hdr->proto;\n",
      "\t\tnhoff += PPPOE_SES_HLEN;\n",
      "\t\tswitch (proto) {\n",
      "\t\tcase __constant_htons(PPP_IP):\n",
      "\t\t\tgoto ip;\n",
      "\t\tcase __constant_htons(PPP_IPV6):\n",
      "\t\t\tgoto ipv6;\n",
      "\t\tdefault:\n",
      "\t\t\treturn false;\n",
      "\t\t}\n",
      "\t}\n",
      "\tdefault:\n",
      "\t\treturn false;\n",
      "\t}\n",
      "\n",
      "\tswitch (ip_proto) {\n",
      "\tcase IPPROTO_GRE: {\n",
      "\t\tstruct gre_hdr {\n",
      "\t\t\t__be16 flags;\n",
      "\t\t\t__be16 proto;\n",
      "\t\t} *hdr, _hdr;\n",
      "\n",
      "\t\thdr = skb_header_pointer(skb, nhoff, sizeof(_hdr), &_hdr);\n",
      "\t\tif (!hdr)\n",
      "\t\t\treturn false;\n",
      "\t\t/*\n",
      "\t\t * Only look inside GRE if version zero and no\n",
      "\t\t * routing\n",
      "\t\t */\n",
      "\t\tif (!(hdr->flags & (GRE_VERSION|GRE_ROUTING))) {\n",
      "\t\t\tproto = hdr->proto;\n",
      "\t\t\tnhoff += 4;\n",
      "\t\t\tif (hdr->flags & GRE_CSUM)\n",
      "\t\t\t\tnhoff += 4;\n",
      "\t\t\tif (hdr->flags & GRE_KEY)\n",
      "\t\t\t\tnhoff += 4;\n",
      "\t\t\tif (hdr->flags & GRE_\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e48afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
